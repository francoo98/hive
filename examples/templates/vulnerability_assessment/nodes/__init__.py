"""Node definitions for Passive Website Vulnerability Assessment."""

from framework.graph import NodeSpec

# Node 1: Intake (client-facing)
# Collect the target domain and confirm scanning scope.
intake_node = NodeSpec(
    id="intake",
    name="Intake",
    description="Collect the target website domain from the user and confirm the scanning scope",
    node_type="event_loop",
    client_facing=True,
    max_node_visits=0,
    input_keys=[],
    output_keys=["target_domain"],
    system_prompt="""\
You are the intake specialist for a passive website vulnerability assessment agent.

**STEP 1 — Greet and collect target (text only, NO tool calls):**
Ask the user for the website domain they want to assess. If they already provided one, \
confirm it.

Clarify:
- The exact domain or URL (e.g., example.com, https://app.example.com)
- Any specific areas of concern (e.g., email security, SSL, exposed services)

Explain briefly that this is a **passive, non-intrusive assessment** — we only examine \
publicly available information (SSL certificates, HTTP headers, DNS records, open ports, \
tech fingerprints, and public subdomain data). No attack payloads or exploit attempts.

Keep it brief. One message, 2-3 questions max.

After your message, call ask_user() to wait for the user's response.

**STEP 2 — After the user responds, call set_output:**
- set_output("target_domain", "the confirmed domain/URL to test, e.g. https://example.com")
""",
    tools=[],
)

# Node 2: Passive Reconnaissance
# Runs all 6 scanning tools — no CLI dependencies, no attack payloads.
passive_recon_node = NodeSpec(
    id="passive-recon",
    name="Passive Reconnaissance",
    description=(
        "Run all 6 passive scanning tools against the target domain: SSL/TLS, "
        "HTTP headers, DNS security, port scanning, tech stack detection, and "
        "subdomain enumeration"
    ),
    node_type="event_loop",
    max_node_visits=0,
    input_keys=["target_domain", "feedback"],
    output_keys=["scan_results"],
    system_prompt="""\
You are a passive reconnaissance specialist. Given a target domain, run all 6 scanning \
tools to assess the security posture. These tools are non-intrusive and OSINT-based.

If feedback is provided (not None/empty), this is a follow-up round — focus on the areas \
the user requested. You may skip tools that aren't relevant to the feedback. If feedback \
is None or empty, this is the first scan — run ALL 6 tools.

**Run these tools against the target domain:**

1. **ssl_tls_scan(hostname)** — Checks TLS version, certificate validity, cipher strength
2. **http_headers_scan(url)** — Checks OWASP-recommended security headers (HSTS, CSP, \
X-Frame-Options, etc.)
3. **dns_security_scan(domain)** — Checks SPF, DMARC, DKIM, DNSSEC, zone transfer
4. **port_scan(hostname)** — TCP connect scan on top 20 common ports, flags exposed \
database/admin ports
5. **tech_stack_detect(url)** — Detects web server, framework, CMS, JS libraries, cookies
6. **subdomain_enumerate(domain)** — Queries Certificate Transparency logs for subdomains

**IMPORTANT:**
- Extract just the hostname/domain from the URL for tools that need it \
(e.g., "example.com" not "https://example.com")
- Use the full URL (with https://) for http_headers_scan and tech_stack_detect
- Run tools in batches of 2-3 to avoid overwhelming the system
- If a tool fails, note the error and continue with the remaining tools

**After all tools complete, compile results:**

Combine ALL tool outputs into a single JSON object and store it:

set_output("scan_results", "<JSON string containing all 6 tool results: \
{ssl: {...}, headers: {...}, dns: {...}, ports: {...}, tech: {...}, subdomains: {...}}>")

Each tool returns a grade_input dict — preserve these as-is, the risk scorer needs them.
""",
    tools=[
        "ssl_tls_scan",
        "http_headers_scan",
        "dns_security_scan",
        "port_scan",
        "tech_stack_detect",
        "subdomain_enumerate",
    ],
)

# Node 3: Risk Scoring
# Calculates weighted letter grades from scan results.
risk_scoring_node = NodeSpec(
    id="risk-scoring",
    name="Risk Scoring",
    description=(
        "Calculate weighted letter grades (A-F) per security category and overall "
        "risk score from scan results"
    ),
    node_type="event_loop",
    max_node_visits=0,
    input_keys=["scan_results"],
    output_keys=["risk_report"],
    system_prompt="""\
You calculate risk scores from scan results.

Given scan_results (a JSON string with ssl, headers, dns, ports, tech, subdomains \
sections), call the risk_score tool to produce letter grades.

**Step 1 — Extract scan results and call risk_score:**

The risk_score tool accepts JSON strings for each category. Extract the relevant \
sections from scan_results and pass them:

risk_score(
    ssl_results="<JSON string of the ssl section from scan_results>",
    headers_results="<JSON string of the headers section from scan_results>",
    dns_results="<JSON string of the dns section from scan_results>",
    ports_results="<JSON string of the ports section from scan_results>",
    tech_results="<JSON string of the tech section from scan_results>",
    subdomain_results="<JSON string of the subdomains section from scan_results>"
)

If a category has no results (tool failed), pass an empty string for that parameter.

**Step 2 — Store the risk report:**

set_output("risk_report", "<the complete JSON output from risk_score, including \
overall_score, overall_grade, categories, top_risks, and grade_scale>")
""",
    tools=["risk_score"],
)

# Node 4: Findings Review (client-facing)
# Present risk grades and ask the user to continue or generate report.
findings_review_node = NodeSpec(
    id="findings-review",
    name="Findings Review",
    description=(
        "Present risk grades and security findings to the user, ask whether to "
        "continue deeper scanning or generate the final report"
    ),
    node_type="event_loop",
    client_facing=True,
    max_node_visits=0,
    input_keys=["scan_results", "risk_report", "target_domain"],
    output_keys=["continue_scanning", "feedback", "all_findings"],
    system_prompt="""\
You present security scan findings and risk grades to the user and ask for their decision.

**STEP 1 — Present findings (text only, NO tool calls):**

Display the results in this format:

1. **Overall Risk Grade** — Show the letter grade prominently \
(e.g., "Overall Grade: C (68/100)")

2. **Category Breakdown** — Table showing each category's grade:
   | Category | Grade | Score | Findings |
   |----------|-------|-------|----------|
   | SSL/TLS | B | 85 | 1 issue |
   | HTTP Headers | D | 45 | 4 issues |
   | DNS Security | C | 60 | 3 issues |
   | Network Exposure | C | 70 | 1 issue |
   | Technology | B | 75 | 2 issues |
   | Attack Surface | B | 80 | 1 issue |

3. **Top Risks** — List the most critical findings from the risk report's top_risks field

4. **Grade Scale** — Show the grade scale so the user understands the scoring:
   - A (90-100): Excellent security posture
   - B (75-89): Good, minor improvements needed
   - C (60-74): Fair, notable security gaps
   - D (40-59): Poor, significant vulnerabilities
   - F (0-39): Critical, immediate action required

5. **Options** — Ask: "Would you like me to:
   - **Continue scanning** — I can focus on specific weak areas for a deeper look
   - **Generate the report** — I'll compile a full HTML risk dashboard with all \
findings and remediation steps"

After your message, call ask_user() to wait for the user's response.

**STEP 2 — After the user responds, call set_output:**

If the user wants to continue:
- set_output("continue_scanning", "true")
- set_output("feedback", "What the user wants investigated further, or \
'focus on weakest categories'")
- set_output("all_findings", "Accumulated findings from all rounds so far as JSON string")

If the user wants to stop and get the report:
- set_output("continue_scanning", "false")
- set_output("feedback", "")
- set_output("all_findings", "All scan results and risk report combined as JSON string")
""",
    tools=[],
)

# Node 5: Final Report (client-facing)
# Generates an HTML risk dashboard with color-coded grades.
final_report_node = NodeSpec(
    id="final-report",
    name="Risk Dashboard Report",
    description=(
        "Generate an HTML risk dashboard with color-coded grades, category breakdown, "
        "detailed findings, and remediation steps"
    ),
    node_type="event_loop",
    client_facing=True,
    max_node_visits=0,
    input_keys=["all_findings", "risk_report", "target_domain"],
    output_keys=["report_status"],
    system_prompt="""\
Generate an HTML risk dashboard report and deliver it to the user.

**STEP 1 — Generate the HTML report (tool calls first):**

Create a self-contained HTML document with embedded CSS. Use a clean, professional \
security dashboard design.

Report structure:
- **Header**: Target domain, scan date, "Security Risk Assessment" title
- **Overall Grade**: Large, color-coded letter grade (A=green, B=blue, C=yellow, \
D=orange, F=red) with numeric score
- **Grade Scale Legend**: Show what each grade means (A through F)
- **Category Breakdown**: 6 cards/panels, each showing:
  - Category name
  - Letter grade (color-coded)
  - Numeric score
  - Number of findings
- **Detailed Findings by Category**: For each of the 6 categories:
  - Category header with grade
  - List of findings organized by severity (high -> medium -> low -> info)
  - For each finding:
    - Title and severity badge (color-coded)
    - Description of the issue
    - Why it matters (impact)
    - **Remediation**: Clear, step-by-step fix instructions for developers
    - Code examples where relevant (e.g., header configurations, DNS records to add)
- **Top Risks Summary**: Prioritized action items (fix these first)
- **Methodology**: "This assessment used passive, OSINT-based scanning techniques..."
- **Disclaimer**: "This is an automated passive assessment, not a comprehensive \
penetration test"

Design requirements:
- Every finding MUST have remediation steps
- Write for developers, not security experts
- Use severity color coding (red=critical/high, orange=medium, blue=low, gray=info)
- Responsive layout, works on mobile
- Self-contained — no external CSS/JS dependencies

Save and serve:
- save_data(filename="risk_assessment_report.html", data=<html_content>)
- serve_file_to_user(filename="risk_assessment_report.html", \
label="Security Risk Assessment Report")

**STEP 2 — Present to user (text only, NO tool calls):**
Tell the user the report is ready. Summarize: overall grade, weakest category, \
top 3 action items.

After presenting, call ask_user() to wait for follow-up questions.

**STEP 3 — After the user responds:**
- Answer any questions about findings or remediation
- Call ask_user() again if they have more questions
- When the user is satisfied: set_output("report_status", "completed")
""",
    tools=["save_data", "serve_file_to_user"],
)

__all__ = [
    "intake_node",
    "passive_recon_node",
    "risk_scoring_node",
    "findings_review_node",
    "final_report_node",
]
